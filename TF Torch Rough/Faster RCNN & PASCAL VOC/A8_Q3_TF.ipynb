{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/gopalbhattrai/pascal-voc-2012-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.52G/3.52G [17:22<00:00, 3.63MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['VOC2012_test', 'VOC2012_train_val']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "path = kagglehub.dataset_download(\"gopalbhattrai/pascal-voc-2012-dataset\")\n",
    "\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(f'{path}/VOC2012_train_val/VOC2012_train_val')\n",
    "annotations = f'{path}/VOC2012_train_val/VOC2012_train_val/Annotations'\n",
    "images = f'{path}/VOC2012_train_val/VOC2012_train_val/JPEGImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['2007_000027.xml',\n",
       "  '2007_000032.xml',\n",
       "  '2007_000033.xml',\n",
       "  '2007_000039.xml',\n",
       "  '2007_000042.xml'],\n",
       " ['2007_000027.jpg',\n",
       "  '2007_000032.jpg',\n",
       "  '2007_000033.jpg',\n",
       "  '2007_000039.jpg',\n",
       "  '2007_000042.jpg'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(annotations)[:5], os.listdir(images)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_label(xml):\n",
    "    import xml.etree.ElementTree as ET\n",
    "\n",
    "    tree = ET.parse(xml)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    bbox = {}\n",
    "    for child in root:\n",
    "        if child.tag != 'object': continue\n",
    "        for child2 in child:\n",
    "            if child2.tag != 'bndbox': continue\n",
    "            for child3 in child2:\n",
    "                bbox[child3.tag] = int(child3.text)\n",
    "    return bbox['xmin'], bbox['xmax'], bbox['ymin'], bbox['ymax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17125 files.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "\n",
    "X = keras.preprocessing.image_dataset_from_directory(\n",
    "    images,\n",
    "    seed=42,\n",
    "    label_mode=None,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "y = tf.data.Dataset.list_files(f\"{annotations}/*.xml\", seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.zip(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML Env Paths\\.cache\\kagglehub\\datasets\\gopalbhattrai\\pascal-voc-2012-dataset\\versions\\1\\VOC2012_train_val\\VOC2012_train_val\\Annotations\\2010_000661.xml\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset:\n",
    "    print(bytes.decode(y.numpy()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image = tf.image.resize(image, size=(300,300))\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on subset\n",
    "dataset = dataset.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_xml_to_label(y):\n",
    "    return tf.py_function(lambda x: xml_to_label(bytes.decode(x.numpy())), inp=[y], Tout=[tf.int64, tf.int64, tf.int64, tf.int64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = dataset.map(lambda x, y: (preprocess(x), tf_xml_to_label(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 74 239 104 375], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x, y in processed_dataset:\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = processed_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "pretrained = hub.KerasLayer(\"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\", input_shape=(300,300,3), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Lambda(pretrained),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1024, activation='relu'),\n",
    "    keras.layers.Dense(4, activation='relu'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-2),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[keras.metrics.MeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = processed_dataset.take(5)\n",
    "train_dataset = processed_dataset.skip(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\dev\\miniconda\\envs\\faiac\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\dev\\miniconda\\envs\\faiac\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'keras_layer_2' (type KerasLayer).\n\nKerasLayer output does not contain the output key default (available: dict_keys(['detection_scores', 'detection_class_names', 'detection_class_entities', 'detection_boxes', 'detection_class_labels'])).\n\nCall arguments received by layer 'keras_layer_2' (type KerasLayer):\n  • inputs=tf.Tensor(shape=(None, 300, 300, 3), dtype=float32)\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_dataset, validation_data\u001b[38;5;241m=\u001b[39mtest_dataset)\n",
      "File \u001b[1;32mc:\\dev\\miniconda\\envs\\faiac\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\dev\\miniconda\\envs\\faiac\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\dev\\miniconda\\envs\\faiac\\Lib\\site-packages\\tensorflow_hub\\keras_layer.py:260\u001b[0m, in \u001b[0;36mKerasLayer.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifying `output_key` is forbidden if output \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    258\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not a dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(result))\n\u001b[0;32m    259\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m--> 260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKerasLayer output does not contain the output key \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(available: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_key, result\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[0;32m    263\u001b[0m   result \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_key]\n\u001b[0;32m    265\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_output_shape_if_set(inputs, result)\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer 'keras_layer_2' (type KerasLayer).\n\nKerasLayer output does not contain the output key default (available: dict_keys(['detection_scores', 'detection_class_names', 'detection_class_entities', 'detection_boxes', 'detection_class_labels'])).\n\nCall arguments received by layer 'keras_layer_2' (type KerasLayer):\n  • inputs=tf.Tensor(shape=(None, 300, 300, 3), dtype=float32)\n  • training=None"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
